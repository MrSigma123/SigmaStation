\documentclass[a4paper,12pt]{article}

% Packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{margin=1in}

\begin{document}

\title{Understanding and Applying Linear Regression}
\author{}
\date{}
\maketitle

\tableofcontents

\newpage

\section{Introduction to Linear Regression}
Linear regression is a statistical method for modeling the relationship between a dependent variable (target) and one or more independent variables (features). It is widely used in predictive modeling, where the goal is to predict an outcome based on given inputs.

Linear regression assumes a linear relationship between the independent variables and the dependent variable. The general form of the linear regression equation is:
\[
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_n X_n + \epsilon
\]
where:
\begin{itemize}
    \item $Y$: Dependent variable (target)
    \item $X_1, X_2, \ldots, X_n$: Independent variables (features)
    \item $\beta_0$: Intercept
    \item $\beta_1, \beta_2, \ldots, \beta_n$: Coefficients of the independent variables
    \item $\epsilon$: Error term
\end{itemize}

\section{Key Concepts}

\subsection{Assumptions of Linear Regression}
Linear regression relies on the following assumptions:
\begin{enumerate}
    \item \textbf{Linearity}: The relationship between independent variables and the dependent variable is linear.
    \item \textbf{Independence}: The residuals (errors) are independent.
    \item \textbf{Homoscedasticity}: The variance of residuals is constant across all levels of the independent variables.
    \item \textbf{Normality}: Residuals are normally distributed.
\end{enumerate}

\subsection{Types of Linear Regression}
\begin{itemize}
    \item \textbf{Simple Linear Regression}: Involves one independent variable.
    \item \textbf{Multiple Linear Regression}: Involves two or more independent variables.
\end{itemize}

\section{Steps to Apply Linear Regression}

\subsection{Step 1: Data Collection}
Gather data that includes both the dependent variable and the independent variables.

\subsection{Step 2: Exploratory Data Analysis (EDA)}
Perform EDA to understand the relationships between variables. Use scatter plots, correlation matrices, and summary statistics.

\subsection{Step 3: Data Preprocessing}
\begin{itemize}
    \item Handle missing values.
    \item Normalize or standardize features if necessary.
    \item Encode categorical variables using techniques like one-hot encoding.
\end{itemize}

\subsection{Step 4: Splitting the Data}
Split the data into training and testing sets, typically using an 80-20 or 70-30 ratio.

\subsection{Step 5: Fitting the Model}
Fit the linear regression model to the training data. The goal is to estimate the coefficients $\beta_0, \beta_1, \ldots, \beta_n$ that minimize the residual sum of squares (RSS):
\[
\text{RSS} = \sum_{i=1}^n \left(Y_i - (\beta_0 + \beta_1 X_{1i} + \ldots + \beta_n X_{ni})\right)^2
\]

\subsection{Step 6: Evaluating the Model}
Evaluate the model using metrics such as:
\begin{itemize}
    \item Mean Absolute Error (MAE)
    \item Mean Squared Error (MSE)
    \item Root Mean Squared Error (RMSE)
    \item $R^2$ (coefficient of determination)
\end{itemize}

\subsection{Step 7: Making Predictions}
Use the trained model to make predictions on new data:
\[
\hat{Y} = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_n X_n
\]

\section{Applications of Linear Regression}
\begin{itemize}
    \item \textbf{Business}: Sales forecasting, demand analysis.
    \item \textbf{Healthcare}: Predicting patient outcomes, medical costs.
    \item \textbf{Finance}: Stock price prediction, risk analysis.
    \item \textbf{Social Sciences}: Understanding relationships between variables in surveys.
\end{itemize}

\section{Example: Simple Linear Regression}
Suppose we have data on house prices ($Y$) and the size of the house ($X$).
\subsection{Step 1: Dataset}
\begin{tabular}{|c|c|}
\hline
House Size (sq. ft.) & Price (\$) \\
\hline
1000 & 200,000 \\
1500 & 250,000 \\
2000 & 300,000 \\
\hline
\end{tabular}

\subsection{Step 2: Fit the Model}
Fit a simple linear regression model:
\[
Y = \beta_0 + \beta_1 X
\]
Assume $\beta_0 = 100,000$ and $\beta_1 = 100$.

\subsection{Step 3: Prediction}
For a house of 1800 sq. ft., predict the price:
\[
Y = 100,000 + 100 \cdot 1800 = 280,000
\]

\section{Conclusion}
Linear regression is a foundational technique in predictive modeling. By understanding its assumptions, mathematical basis, and practical application, you can use it to uncover insights and make informed predictions in various fields.

\end{document}
